{
 "metadata": {
  "name": "",
  "signature": "sha256:33ac8482de9a2e268e2fa700c589dfb45309a12ef0ce5f5517d8f04e2ff602d7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload\n",
      "%autoreload 2\n",
      "\n",
      "from __future__ import division\n",
      "\n",
      "import collections as cl\n",
      "\n",
      "import numpy as np\n",
      "import numpy.random as rn\n",
      "import pylab as pl\n",
      "import pandas as pd\n",
      "\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The autoreload extension is already loaded. To reload it, use:\n",
        "  %reload_ext autoreload\n"
       ]
      }
     ],
     "prompt_number": 139
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def _sample_c(nfeatures, ngroups, zeta):\n",
      "    \"\"\"Generate indicator variables for each transcript\"\"\"\n",
      "\n",
      "    ## allocate space\n",
      "    c = np.zeros((nfeatures, ngroups), dtype='int')\n",
      "    \n",
      "    ## The first column of c is all zeros. Sample the second column of c\n",
      "    w = np.r_[1, zeta]\n",
      "    c[:, 1] = rn.choice(w.size, nfeatures, p=w / np.sum(w))\n",
      "    \n",
      "    ## continue if more than 2 groups are requested\n",
      "    if ngroups > 2:\n",
      "        for i in range(2, ngroups):\n",
      "            ## find occupancies\n",
      "            occ = [c[:, :i] == j for j in range(i+1)]\n",
      "            occ = np.sum(occ, 2, dtype='float').T\n",
      "            occ[range(nfeatures), np.max(c)+1] = zeta\n",
      "            w = occ / np.sum(occ, 1).reshape(-1, 1)\n",
      "            c[:, i] = [rn.choice(wi.size, p=wi) for wi in w]\n",
      "\n",
      "    ##\n",
      "    return c\n",
      "\n",
      "##\n",
      "\n",
      "def _sample_delta(c, fraction_up, fraction_down, dsize):\n",
      "    \"\"\"Generate fold changes for each transcript\"\"\"\n",
      "    \n",
      "    nfeatures, ngroups = c.shape\n",
      "    \n",
      "    ## allocate space \n",
      "    delta = np.zeros((nfeatures, ngroups))\n",
      "    \n",
      "    ## delta's for non-differentially expressed transcripts\n",
      "    delta[c == 0] = 1\n",
      "    \n",
      "    ## delta's for differentially expressed transcripts\n",
      "    for i in range(1, np.max(c) + 1):\n",
      "        ## sample indicators for up- and down-regulation \n",
      "        x = rn.choice([1,-1], (nfeatures, 1), p=[fraction_up,fraction_down])\n",
      "\n",
      "        ## find positions of up- and down-regulated transcripts \n",
      "        up = np.logical_and(c == i, x == 1) \n",
      "        down = np.logical_and(c == i, x == -1)           \n",
      "\n",
      "        ## sample delta's for up- and down-regulated transcripts\n",
      "        rup = dsize + rn.exponential(size=(nfeatures, 1))\n",
      "        rdown = 1 / (dsize + rn.exponential(size=(nfeatures, 1)))\n",
      "\n",
      "        delta[up] = np.tile(rup, (1, ngroups))[up]\n",
      "        delta[down] = np.tile(rdown, (1, ngroups))[down]\n",
      "\n",
      "    ##\n",
      "    return delta\n",
      "\n",
      "## \n",
      "\n",
      "def generate_data_matrix(nfeatures=1000, ngroups=2, nreplicas=3, zeta=0.1, fraction_up=0.5, fraction_down=0.5, \n",
      "                         lib_depth=1e7, min_fact=0.7, max_fact=1.4, dsize=1.5, pars=None):\n",
      "    \"\"\"Generate a matrix of count data\"\"\"\n",
      "    \n",
      "    ## a dictionary of the function arguments\n",
      "    args = locals()\n",
      "    \n",
      "    ## sample indicator variables for differential expression\n",
      "    c = _sample_c(nfeatures, ngroups, zeta)\n",
      "\n",
      "    ## sample fold changes\n",
      "    delta = _sample_delta(c, fraction_up, fraction_down, dsize)\n",
      "    \n",
      "    ## sample library sizes\n",
      "    nsamples = nreplicas * ngroups if np.size(nreplicas) == 1 else np.sum(nreplicas)\n",
      "    facs = min_fact + (max_fact - min_fact) * rn.rand(nsamples)\n",
      "    lib_sizes = lib_depth * facs    \n",
      "    \n",
      "    ## sample names and groups\n",
      "    sample_names = [\"sample%d\" % x for x in range(1,nsamples+1)]\n",
      "    group_names = [\"group%d\" % x for x in range(1,ngroups+1)]\n",
      "    groups = np.repeat(group_names, nreplicas)\n",
      "    \n",
      "    ## sample mu and phi\n",
      "    pars = np.loadtxt('pars.txt') if pars is None else pars  \n",
      "    idxs = rn.choice(len(pars), (nfeatures, 1), replace=False) \n",
      "    phi, mu = pars[idxs, [0]], pars[idxs, [1]]    \n",
      "    mu_ = mu * np.repeat(delta, nreplicas, axis=1)\n",
      "    mu_ /= np.sum(mu_, 0)\n",
      "    mu_ *= lib_sizes\n",
      "    \n",
      "    ## sample counts\n",
      "    shape = 1 / phi\n",
      "    scale = mu_ * phi\n",
      "    rates = rn.gamma(shape, scale)\n",
      "    counts = rn.poisson(rates)\n",
      "    \n",
      "    ## construct dictionary for simulated data\n",
      "    sim = cl.OrderedDict((\n",
      "        ('counts', pd.DataFrame(counts, columns=sample_names)),\n",
      "        ('lib_sizes', pd.DataFrame(lib_sizes, index=sample_names, columns=['sizes']).T),\n",
      "        ('groups', groups),\n",
      "        ('mu', mu),\n",
      "        ('phi', phi),\n",
      "        ('delta', delta),\n",
      "        ('c', c),\n",
      "        ('args', args)\n",
      "    ))\n",
      "    \n",
      "    ## \n",
      "    return sim\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 140
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data3 = generate_data_matrix(nfeatures=10000, nreplicas=5, ngroups=5); "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 143,
       "text": [
        "965"
       ]
      }
     ],
     "prompt_number": 143
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle as pkl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 127
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "raw = data3['counts']; raw.to_csv('simdata3.txt', sep='\\t')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 149
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.sum(data1['c'][:, 1]!=data1['c'][:, 2])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 146,
       "text": [
        "931"
       ]
      }
     ],
     "prompt_number": 146
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('simdata3.pkl','wb') as f:\n",
      "    pkl.dump(data3, f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 152
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}